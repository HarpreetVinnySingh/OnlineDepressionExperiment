{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8jAU5SJClml4",
        "outputId": "0c36af5e-14dc-4ca7-f846-559a0ddd4256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "progress...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import statistics\n",
        "from math import nan, isnan\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "path = '/content/drive/MyDrive/RCData/'\n",
        "\n",
        "all_files = glob.glob(path+'*.csv')\n",
        "\n",
        "for filename in all_files:\n",
        "\n",
        "\n",
        "\n",
        "  #Reading data\n",
        "  Origin = pd.read_csv(filename,usecols=['ID','Task_Order','JS_Task','Buttons1','GMBM_Set','Positive_Order',\n",
        "                                                'Person_Task_Order','Buttons2','SEX','Education','Age',\n",
        "                                                        '1Shape','1Congruence','1RT','1Score',\n",
        "                                                        '2Character','2Shape','2Congruence','2RT',\n",
        "                                                        '2Score','Health group','Treatment','BDI_Total','GAD7_Total','RRS_Total','Rosenberg_Total2',\n",
        "                                                  'Cognitive_Total','Somatic_af_Total','G_me_RT_Matched','B_me_RT_Matched','G_other_RT_Matched','B_other_RT_Matched',\n",
        "                                                  'Self_RT_Matched','Other_RT_Matched','TimeDur_POSself','TimeDur_NEGself','TimeDur_POSother','TimeDur_NEGother'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Function to get the mean of a list\n",
        "  def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "\n",
        "  #Created a function to calculate variance, the one in the statistics module seemed to not work with my data for an unknown reason\n",
        "  def variance(data):\n",
        "    # Number of observations\n",
        "    n = len(data)\n",
        "    # Mean of the data\n",
        "    mean = sum(data) / n\n",
        "    # Square deviations\n",
        "    deviations = [(x - mean) ** 2 for x in data]\n",
        "    # Variance\n",
        "    variance = sum(deviations) / n\n",
        "    return variance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #EZ Diffusion model code taken from the internet, tested and works the same as Wagenmakers online tool\n",
        "  # EZ Diffusion model functions\n",
        "  def logit(p):\n",
        "      return math.log(p/(1-p))\n",
        "\n",
        "  def ezdiff(MRT,VRT,p):\n",
        "\n",
        "      if p == 0:\n",
        "          print(\"Oops, only errors for subject \"+ \"!\")\n",
        "      elif p == 0.5:\n",
        "          print(\"Oops, chance performance for \"+ \"!\")\n",
        "      elif p == 1:\n",
        "          print(\"Oops,  only correct responses for \"+ \"!\")\n",
        "      \n",
        "      s = 0.1\n",
        "      s2 = s*s # scaling parameter squared\n",
        "      L = logit(p)\n",
        "      x1 = (L*p*p - L*p + p - 0.5)\n",
        "      x = L * x1 / VRT\n",
        "      v = np.sign(p - 0.5) * s*math.pow(x,0.25)\n",
        "      a = s2*logit(p)/v\n",
        "      y = -v*a/s2\n",
        "      MDT = (a/(2*v))*(1-math.exp(y))/(1+math.exp(y))\n",
        "      Ter = MRT - MDT\n",
        "      \n",
        "      return([v,a,Ter])\n",
        "\n",
        "\n",
        "  #Time duration sum code, this calculates the amount of time taken for participants to write word attributions for GMBMGOBO\n",
        "\n",
        "  GM_Time = Origin['TimeDur_POSself'].sum()\n",
        "  BM_Time = Origin['TimeDur_NEGself'].sum()\n",
        "  GO_Time = Origin['TimeDur_POSother'].sum()\n",
        "  BO_Time = Origin['TimeDur_NEGother'].sum()\n",
        "\n",
        "\n",
        "  #Percentage correct\n",
        "  Self_Percent = Origin.groupby([\"1Shape\",\"1Congruence\"])[\"1Score\"].mean()[0]\n",
        "  Other_Percent = Origin.groupby([\"1Shape\",\"1Congruence\"])[\"1Score\"].mean()[3]\n",
        "\n",
        "  BM_Percent = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2Score\"].mean()[0]\n",
        "  GM_Percent = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2Score\"].mean()[4]\n",
        "  BO_Percent = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2Score\"].mean()[2]\n",
        "  GO_Percent = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2Score\"].mean()[6]\n",
        "\n",
        "\n",
        "  #These if statements add artificial error into perfectly correct scores by a degree of 1% so that the EZ algorithm works\n",
        "  if Self_Percent == 1:\n",
        "    Self_Percent = Self_Percent - 0.01\n",
        "\n",
        "  if Self_Percent == 0.5:\n",
        "    Self_Percent = Self_Percent - 0.01\n",
        "\n",
        "  if Other_Percent == 1:\n",
        "    Other_Percent = Other_Percent - 0.01\n",
        "\n",
        "  if Other_Percent == 0.5:\n",
        "    Other_Percent = Other_Percent - 0.01\n",
        "\n",
        "  if GM_Percent == 1:\n",
        "    GM_Percent = GM_Percent - 0.01\n",
        "\n",
        "  if GM_Percent == 0.5:\n",
        "    GM_Percent = GM_Percent - 0.01\n",
        "\n",
        "  if BM_Percent == 1:\n",
        "    BM_Percent = BM_Percent - 0.01\n",
        "\n",
        "  if BM_Percent == 0.5:\n",
        "    BM_Percent = BM_Percent - 0.01\n",
        "\n",
        "  if GO_Percent == 1:\n",
        "    GO_Percent = GO_Percent - 0.01\n",
        "\n",
        "  if GO_Percent == 0.5:\n",
        "    GO_Percent = GO_Percent - 0.01\n",
        "\n",
        "  if BO_Percent == 1:\n",
        "    BO_Percent = BO_Percent - 0.01\n",
        "\n",
        "  if BO_Percent == 0.5:\n",
        "    BO_Percent = BO_Percent - 0.01\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Mean reaction time\n",
        "  Self_RT = Origin['Self_RT_Matched'][0]\n",
        "  Other_RT = Origin['Other_RT_Matched'][0]\n",
        "  B_me_RT = Origin['B_me_RT_Matched'][0]\n",
        "  G_other_RT = Origin['G_other_RT_Matched'][0]\n",
        "  G_me_RT = Origin['G_me_RT_Matched'][0]\n",
        "  B_other_RT = Origin['B_other_RT_Matched'][0]\n",
        "\n",
        "\n",
        "  #Variance list preparation\n",
        "\n",
        "  Self_RT_Lists = Origin.loc[(Origin['1Shape'] == 'Self') & (Origin['1Congruence'] == 'congruent')]\n",
        "  SRL = Self_RT_Lists['1RT']\n",
        "  SRL_List = SRL.values.tolist()\n",
        "  SRT_list = SRL_List\n",
        "  Self_RT_Numbers = [item for item in SRT_list if not(pd.isnull(item)) == True]\n",
        "\n",
        "  Stranger_RT_Lists = Origin.loc[(Origin['1Shape'] == 'Stranger') & (Origin['1Congruence'] == 'congruent')]\n",
        "  ORL = Stranger_RT_Lists['1RT']\n",
        "  ORL_List = ORL.values.tolist()\n",
        "  ORT_list = ORL_List\n",
        "  Stranger_RT_Numbers = [item for item in ORT_list if not(pd.isnull(item)) == True]\n",
        "\n",
        "  GM_RT_Lists = Origin.loc[(Origin['2Shape'] == 'Good_me') & (Origin['2Congruence'] == 'congruent')]\n",
        "  GMRL = GM_RT_Lists['2RT']\n",
        "  GMRL_List = GMRL.values.tolist()\n",
        "  GMRT_list = GMRL_List\n",
        "  GM_RT_Numbers = [item for item in GMRT_list if not(pd.isnull(item)) == True]\n",
        "\n",
        "  BM_RT_Lists = Origin.loc[(Origin['2Shape'] == 'Bad_me') & (Origin['2Congruence'] == 'congruent')]\n",
        "  BMRL = BM_RT_Lists['2RT']\n",
        "  BMRL_List = BMRL.values.tolist()\n",
        "  BMRT_list = BMRL_List\n",
        "  BM_RT_Numbers = [item for item in BMRT_list if not(pd.isnull(item)) == True]\n",
        "\n",
        "\n",
        "  GO_RT_Lists = Origin.loc[(Origin['2Shape'] == 'Good_other') & (Origin['2Congruence'] == 'congruent')]\n",
        "  GORL = GO_RT_Lists['2RT']\n",
        "  GORL_List = GORL.values.tolist()\n",
        "  GORT_list = GORL_List\n",
        "  GO_RT_Numbers = [item for item in GORT_list if not(pd.isnull(item)) == True]\n",
        "\n",
        "\n",
        "  BO_RT_Lists = Origin.loc[(Origin['2Shape'] == 'Bad_other') & (Origin['2Congruence'] == 'congruent')]\n",
        "  BORL = BO_RT_Lists['2RT']\n",
        "  BORL_List = BORL.values.tolist()\n",
        "  BORT_list = BORL_List\n",
        "  BO_RT_Numbers = [item for item in BORT_list if not(pd.isnull(item)) == True]\n",
        "\n",
        "  #Variance\n",
        "\n",
        "  Self_Variance = variance(Self_RT_Numbers)\n",
        "  Stranger_Variance = variance(Stranger_RT_Numbers)\n",
        "  GM_Variance = variance(GM_RT_Numbers)\n",
        "  BM_Variance = variance(BM_RT_Numbers)\n",
        "  GO_Variance = variance(GO_RT_Numbers)\n",
        "  BO_Variance = variance(BO_RT_Numbers)\n",
        "\n",
        "\n",
        "  #EZ-diffusion calculation\n",
        "\n",
        "  Self_v = ezdiff(Self_RT,Self_Variance,Self_Percent)[0]\n",
        "  Stranger_v = ezdiff(Other_RT,Stranger_Variance,Other_Percent)[0]\n",
        "\n",
        "  v_bias = Stranger_v - Self_v\n",
        "\n",
        "  GM_v = ezdiff(G_me_RT,GM_Variance,GM_Percent)[0]\n",
        "  BM_v = ezdiff(B_me_RT,BM_Variance,BM_Percent)[0]\n",
        "\n",
        "  GO_v = ezdiff(G_other_RT,GO_Variance,GO_Percent)[0]\n",
        "  BO_v = ezdiff(B_other_RT,BO_Variance,BO_Percent)[0]\n",
        "\n",
        "  Self_a = ezdiff(Self_RT,Self_Variance,Self_Percent)[1]\n",
        "  Stranger_a = ezdiff(Other_RT,Stranger_Variance,Other_Percent)[1]\n",
        "\n",
        "  Self_Ter = ezdiff(Self_RT,Self_Variance,Self_Percent)[2]\n",
        "  Stranger_Ter = ezdiff(Other_RT,Stranger_Variance,Other_Percent)[2]\n",
        "\n",
        "  GM_a = ezdiff(G_me_RT,GM_Variance,GM_Percent)[1]\n",
        "  BM_a = ezdiff(B_me_RT,BM_Variance,BM_Percent)[1]\n",
        "\n",
        "  GO_a = ezdiff(G_other_RT,GO_Variance,GO_Percent)[1]\n",
        "  BO_a = ezdiff(B_other_RT,BO_Variance,BO_Percent)[1]\n",
        "\n",
        "  GM_Ter = ezdiff(G_me_RT,GM_Variance,GM_Percent)[2]\n",
        "  BM_Ter = ezdiff(B_me_RT,BM_Variance,BM_Percent)[2]\n",
        "\n",
        "  GO_Ter = ezdiff(G_other_RT,GO_Variance,GO_Percent)[2]\n",
        "  BO_Ter = ezdiff(B_other_RT,BO_Variance,BO_Percent)[2]\n",
        "\n",
        "\n",
        "  #Valence and person variable creator\n",
        "\n",
        "  Valence_good = ((G_me_RT + G_other_RT)/2)\n",
        "  Valence_bad = ((B_me_RT + B_other_RT)/2)\n",
        "  Person_self = ((G_me_RT + B_me_RT)/2)\n",
        "  Person_other = ((G_other_RT + B_other_RT)/2)\n",
        "\n",
        "  #Cleaning data by removing RT's +/- 3 std. away from mean\n",
        "\n",
        "  Self_Mean = Origin.groupby([\"1Shape\",\"1Congruence\"])[\"1RT\"].mean()[0]\n",
        "  Other_Mean = Origin.groupby([\"1Shape\",\"1Congruence\"])[\"1RT\"].mean()[3]\n",
        "\n",
        "  BM_Mean = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2RT\"].mean()[0]\n",
        "  GM_Mean = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2RT\"].mean()[4]\n",
        "  BO_Mean = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2RT\"].mean()[2]\n",
        "  GO_Mean = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2RT\"].mean()[6]\n",
        "\n",
        "\n",
        "\n",
        "  Self_STD = Origin.groupby([\"1Shape\",\"1Congruence\"])[\"1RT\"].std()[0]\n",
        "  Other_STD = Origin.groupby([\"1Shape\",\"1Congruence\"])[\"1RT\"].std()[3]\n",
        "\n",
        "  BM_STD = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2RT\"].std()[0]\n",
        "  GM_STD = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2RT\"].std()[4]\n",
        "  BO_STD = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2RT\"].std()[2]\n",
        "  GO_STD = Origin.groupby([\"2Shape\",\"2Congruence\"])[\"2RT\"].std()[6]\n",
        "\n",
        "\n",
        "  Self_upper_limit = Self_Mean + 3*Self_STD\n",
        "  Self_lower_limit = Self_Mean + -3*Self_STD\n",
        "\n",
        "  Other_upper_limit = Other_Mean + 3*Other_STD\n",
        "  Other_lower_limit = Other_Mean + -3*Other_STD\n",
        "\n",
        "  BM_upper_limit = BM_Mean + 3*BM_STD\n",
        "  BM_lower_limit = BM_Mean + -3*BM_STD\n",
        "\n",
        "  GM_upper_limit = GM_Mean + 3*GM_STD\n",
        "  GM_lower_limit = GM_Mean + -3*GM_STD\n",
        "\n",
        "  BO_upper_limit = BO_Mean + 3*BO_STD\n",
        "  BO_lower_limit = BO_Mean + -3*BO_STD\n",
        "\n",
        "  GO_upper_limit = GO_Mean + 3*GO_STD\n",
        "  GO_lower_limit = GO_Mean + -3*GO_STD\n",
        "\n",
        "  #Cleaned lists\n",
        "\n",
        "  toofast = 0.2\n",
        "\n",
        "  Self_clean = ([i for i in Self_RT_Numbers if i > Self_lower_limit and i < Self_upper_limit and i > toofast])\n",
        "  Other_clean = ([i for i in Stranger_RT_Numbers if i > Other_lower_limit and i < Other_upper_limit and i > toofast])\n",
        "\n",
        "  BM_clean = ([i for i in BM_RT_Numbers if i > BM_lower_limit and i < BM_upper_limit and i > toofast])\n",
        "  GM_clean = ([i for i in GM_RT_Numbers if i > GM_lower_limit and i < GM_upper_limit and i > toofast])\n",
        "\n",
        "  BO_clean = ([i for i in BO_RT_Numbers if i > BO_lower_limit and i < BO_upper_limit and i > toofast])\n",
        "  GO_clean = ([i for i in GO_RT_Numbers if i > GO_lower_limit and i < GO_upper_limit and i > toofast])\n",
        "\n",
        "  #Cleaned Mean variables\n",
        "  Self_clean_Mean = Average(Self_clean)\n",
        "  Other_clean_Mean = Average(Other_clean)\n",
        "\n",
        "  BM_clean_Mean = Average(BM_clean)\n",
        "  GM_clean_Mean = Average(GM_clean)\n",
        "  BO_clean_Mean = Average(BO_clean)\n",
        "  GO_clean_Mean = Average(GO_clean)\n",
        "\n",
        "  #Cleaned variance\n",
        "\n",
        "  bSelf_Variance = variance(Self_clean)\n",
        "  bStranger_Variance = variance(Other_clean)\n",
        "  bGM_Variance = variance(GM_clean)\n",
        "  bBM_Variance = variance(BM_clean)\n",
        "  bGO_Variance = variance(GO_clean)\n",
        "  bBO_Variance = variance(BO_clean)\n",
        "\n",
        "  #Cleaned EZ-Diffusion modelling\n",
        "\n",
        "  Self_v2 = ezdiff(Self_clean_Mean,bSelf_Variance,Self_Percent)[0]\n",
        "  Stranger_v2 = ezdiff(Other_clean_Mean,bStranger_Variance,Other_Percent)[0]\n",
        "\n",
        "  v_bias2 = Stranger_v2 - Self_v2\n",
        "\n",
        "  GM_v2 = ezdiff(GM_clean_Mean,bGM_Variance,GM_Percent)[0]\n",
        "  BM_v2 = ezdiff(BM_clean_Mean,bBM_Variance,BM_Percent)[0]\n",
        "\n",
        "  GO_v2 = ezdiff(GO_clean_Mean,bGO_Variance,GO_Percent)[0]\n",
        "  BO_v2 = ezdiff(BO_clean_Mean,bBO_Variance,BO_Percent)[0]\n",
        "\n",
        "  Self_a2 = ezdiff(Self_clean_Mean,bSelf_Variance,Self_Percent)[1]\n",
        "  Stranger_a2 = ezdiff(Other_clean_Mean,bStranger_Variance,Other_Percent)[1]\n",
        "\n",
        "  Self_Ter2 = ezdiff(Self_clean_Mean,bSelf_Variance,Self_Percent)[2]\n",
        "  Stranger_Ter2 = ezdiff(Other_clean_Mean,bStranger_Variance,Other_Percent)[2]\n",
        "\n",
        "  GM_a2 = ezdiff(GM_clean_Mean,bGM_Variance,GM_Percent)[1]\n",
        "  BM_a2 = ezdiff(BM_clean_Mean,bBM_Variance,BM_Percent)[1]\n",
        "\n",
        "  GO_a2 = ezdiff(GO_clean_Mean,bGO_Variance,GO_Percent)[1]\n",
        "  BO_a2 = ezdiff(BO_clean_Mean,bBO_Variance,BO_Percent)[1]\n",
        "\n",
        "  GM_Ter2 = ezdiff(GM_clean_Mean,bGM_Variance,GM_Percent)[2]\n",
        "  BM_Ter2 = ezdiff(BM_clean_Mean,bBM_Variance,BM_Percent)[2]\n",
        "\n",
        "  GO_Ter2 = ezdiff(GO_clean_Mean,bGO_Variance,GO_Percent)[2]\n",
        "  BO_Ter2 = ezdiff(BO_clean_Mean,bBO_Variance,BO_Percent)[2]\n",
        "\n",
        "  #Inserting the drift values into the excel file\n",
        "\n",
        "  Origin.insert(0, \"Self_v\",Self_v, True)\n",
        "  Origin.insert(1, \"Stranger_v\",Stranger_v, True)\n",
        "  Origin.insert(2, \"v_bias\",v_bias, True)\n",
        "  Origin.insert(3, \"GM_v\",GM_v, True)\n",
        "  Origin.insert(4, \"BM_v\",BM_v, True)\n",
        "  Origin.insert(5, \"GO_v\",GO_v, True)\n",
        "  Origin.insert(6, \"BO_v\",BO_v, True)\n",
        "\n",
        "  Origin.insert(7, \"Self_a\",Self_a, True)\n",
        "  Origin.insert(8, \"Stranger_a\",Stranger_a, True)\n",
        "\n",
        "  Origin.insert(9, \"GM_a\",GM_a, True)\n",
        "  Origin.insert(10, \"BM_a\",BM_a, True)\n",
        "  Origin.insert(11, \"GO_a\",GO_a, True)\n",
        "  Origin.insert(12, \"BO_a\",BO_a, True)\n",
        "\n",
        "  Origin.insert(13, \"Self_Ter\",Self_v, True)\n",
        "  Origin.insert(14, \"Stranger_Ter\",Stranger_v, True)\n",
        "\n",
        "  Origin.insert(15, \"GM_Ter\",GM_Ter, True)\n",
        "  Origin.insert(16, \"BM_Ter\",BM_Ter, True)\n",
        "  Origin.insert(17, \"GO_Ter\",GO_Ter, True)\n",
        "  Origin.insert(18, \"BO_Ter\",BO_Ter, True)\n",
        "\n",
        "  #Inserting time sum codes\n",
        "\n",
        "  Origin.insert(19, \"GM_Time\",GM_Time, True)\n",
        "  Origin.insert(20, \"BM_Time\",BM_Time, True)\n",
        "  Origin.insert(21, \"GO_Time\",GO_Time, True)\n",
        "  Origin.insert(22, \"BO_Time\",BO_Time, True)\n",
        "\n",
        "  #Inserting percent correct\n",
        "\n",
        "  Origin.insert(23, \"GM_Percent\",GM_Percent, True)\n",
        "  Origin.insert(24, \"BM_Percent\",BM_Percent, True)\n",
        "  Origin.insert(25, \"GO_Percent\",GO_Percent, True)\n",
        "  Origin.insert(26, \"BO_Percent\",BO_Percent, True)\n",
        "\n",
        "  Origin.insert(27, \"Self_Percent\",Self_Percent, True)\n",
        "  Origin.insert(28, \"Other_Percent\",Other_Percent, True)\n",
        "\n",
        "  #Inserting valence and person variables\n",
        " \n",
        "  Origin.insert(29, \"Valence_good\",Valence_good, True)\n",
        "  Origin.insert(30, \"Valence_bad\",Valence_bad, True)\n",
        "  Origin.insert(31, \"Person_self\",Person_self, True)\n",
        "  Origin.insert(32, \"Person_other\",Person_other, True)\n",
        "\n",
        "  #Inserting std. cleaned mean values\n",
        "\n",
        "\n",
        "  Origin.insert(33, \"Self_clean_Mean\",Self_clean_Mean, True)\n",
        "  Origin.insert(34, \"Other_clean_Mean\",Other_clean_Mean, True)\n",
        "\n",
        "  Origin.insert(35, \"GM_clean_Mean\",GM_clean_Mean, True)\n",
        "  Origin.insert(36, \"BM_clean_Mean\",BM_clean_Mean, True)\n",
        "  Origin.insert(37, \"GO_clean_Mean\",GO_clean_Mean, True)\n",
        "  Origin.insert(38, \"BO_clean_Mean\",BO_clean_Mean, True)\n",
        "  \n",
        "  #Inserting the cleaned EZ model data into the data frame\n",
        "\n",
        "  Origin.insert(39, \"Self_v2\",Self_v2, True)\n",
        "  Origin.insert(40, \"Stranger_v2\",Stranger_v2, True)\n",
        "  Origin.insert(41, \"v_bias2\",v_bias2, True)\n",
        "\n",
        "  Origin.insert(42, \"GM_v2\",GM_v2, True)\n",
        "  Origin.insert(43, \"BM_v2\",BM_v2, True)\n",
        "  Origin.insert(44, \"GO_v2\",GO_v2, True)\n",
        "  Origin.insert(45, \"BO_v2\",BO_v2, True)\n",
        "\n",
        "  Origin.insert(46, \"Self_a2\",Self_a2, True)\n",
        "  Origin.insert(8, \"Stranger_a2\",Stranger_a2, True)\n",
        "\n",
        "  Origin.insert(47, \"GM_a2\",GM_a2, True)\n",
        "  Origin.insert(48, \"BM_a2\",BM_a2, True)\n",
        "  Origin.insert(49, \"GO_a2\",GO_a2, True)\n",
        "  Origin.insert(50, \"BO_a2\",BO_a2, True)\n",
        "\n",
        "  Origin.insert(51, \"Self_Ter2\",Self_Ter2, True)\n",
        "  Origin.insert(52, \"Stranger_Ter2\",Stranger_Ter2, True)\n",
        "\n",
        "  Origin.insert(53, \"GM_Ter2\",GM_Ter2, True)\n",
        "  Origin.insert(54, \"BM_Ter2\",BM_Ter2, True)\n",
        "  Origin.insert(55, \"GO_Ter2\",GO_Ter2, True)\n",
        "  Origin.insert(56, \"BO_Ter2\",BO_Ter2, True)\n",
        "\n",
        "  #Shift excess iterations up (831 results for some reason)\n",
        "  \n",
        "  Origin[\"Self_v2\"] = Origin[\"Self_v2\"].shift(-829)\n",
        "  Origin[\"Stranger_v2\"] = Origin[\"Stranger_v2\"].shift(-829)\n",
        "  Origin[\"v_bias2\"] = Origin[\"v_bias2\"].shift(-829)\n",
        "\n",
        "  Origin[\"GM_v2\"] = Origin[\"GM_v2\"].shift(-829)\n",
        "  Origin[\"GO_v2\"] = Origin[\"GO_v2\"].shift(-829)\n",
        "  Origin[\"BO_v2\"] = Origin[\"BO_v2\"].shift(-829)\n",
        "  Origin[\"BM_v2\"] = Origin[\"BM_v2\"].shift(-829)\n",
        "\n",
        "  Origin[\"Self_a2\"] = Origin[\"Self_a2\"].shift(-829)\n",
        "  Origin[\"Stranger_a2\"] = Origin[\"Stranger_a2\"].shift(-829)\n",
        "\n",
        "  Origin[\"GM_a2\"] = Origin[\"GM_a2\"].shift(-829)\n",
        "  Origin[\"GO_a2\"] = Origin[\"GO_a2\"].shift(-829)\n",
        "  Origin[\"BO_a2\"] = Origin[\"BO_a2\"].shift(-829)\n",
        "  Origin[\"BM_a2\"] = Origin[\"BM_a2\"].shift(-829)\n",
        "\n",
        "  Origin[\"Self_Ter2\"] = Origin[\"Self_Ter2\"].shift(-829)\n",
        "  Origin[\"Stranger_Ter2\"] = Origin[\"Stranger_Ter2\"].shift(-829)\n",
        "\n",
        "  Origin[\"GM_Ter2\"] = Origin[\"GM_Ter2\"].shift(-829)\n",
        "  Origin[\"GO_Ter2\"] = Origin[\"GO_Ter2\"].shift(-829)\n",
        "  Origin[\"BO_Ter2\"] = Origin[\"BO_Ter2\"].shift(-829)\n",
        "  Origin[\"BM_Ter2\"] = Origin[\"BM_Ter2\"].shift(-829)\n",
        "\n",
        "  \n",
        "  Origin[\"Self_clean_Mean\"] = Origin[\"Self_clean_Mean\"].shift(-829)\n",
        "  Origin[\"Other_clean_Mean\"] = Origin[\"Other_clean_Mean\"].shift(-829)\n",
        "\n",
        "  Origin[\"GM_clean_Mean\"] = Origin[\"GM_clean_Mean\"].shift(-829)\n",
        "  Origin[\"BM_clean_Mean\"] = Origin[\"BM_clean_Mean\"].shift(-829)\n",
        "  Origin[\"BO_clean_Mean\"] = Origin[\"BO_clean_Mean\"].shift(-829)\n",
        "  Origin[\"GO_clean_Mean\"] = Origin[\"GO_clean_Mean\"].shift(-829)\n",
        "\n",
        "\n",
        "  \n",
        "  Origin[\"Valence_good\"] = Origin[\"Valence_good\"].shift(-829)\n",
        "  Origin[\"Valence_bad\"] = Origin[\"Valence_bad\"].shift(-829)\n",
        "  Origin[\"Person_self\"] = Origin[\"Person_self\"].shift(-829)\n",
        "  Origin[\"Person_other\"] = Origin[\"Person_other\"].shift(-829)\n",
        "\n",
        "\n",
        "\n",
        "  Origin[\"Self_Percent\"] = Origin[\"Self_Percent\"].shift(-829)\n",
        "  Origin[\"Other_Percent\"] = Origin[\"Other_Percent\"].shift(-829)\n",
        "\n",
        "  Origin[\"GM_Percent\"] = Origin[\"GM_Percent\"].shift(-829)\n",
        "  Origin[\"BM_Percent\"] = Origin[\"BM_Percent\"].shift(-829)\n",
        "  Origin[\"GO_Percent\"] = Origin[\"GO_Percent\"].shift(-829)\n",
        "  Origin[\"BO_Percent\"] = Origin[\"BO_Percent\"].shift(-829)\n",
        "\n",
        "\n",
        "  Origin[\"Self_v\"] = Origin[\"Self_v\"].shift(-829)\n",
        "  Origin[\"Stranger_v\"] = Origin[\"Stranger_v\"].shift(-829)\n",
        "  Origin[\"v_bias\"] = Origin[\"v_bias\"].shift(-829)\n",
        "  Origin[\"GM_v\"] = Origin[\"GM_v\"].shift(-829)\n",
        "  Origin[\"GO_v\"] = Origin[\"GO_v\"].shift(-829)\n",
        "  Origin[\"BO_v\"] = Origin[\"BO_v\"].shift(-829)\n",
        "  Origin[\"BM_v\"] = Origin[\"BM_v\"].shift(-829)\n",
        "\n",
        "  Origin[\"Self_a\"] = Origin[\"Self_a\"].shift(-829)\n",
        "  Origin[\"Stranger_a\"] = Origin[\"Stranger_a\"].shift(-829)\n",
        "\n",
        "  Origin[\"GM_a\"] = Origin[\"GM_a\"].shift(-829)\n",
        "  Origin[\"GO_a\"] = Origin[\"GO_a\"].shift(-829)\n",
        "  Origin[\"BO_a\"] = Origin[\"BO_a\"].shift(-829)\n",
        "  Origin[\"BM_a\"] = Origin[\"BM_a\"].shift(-829)\n",
        "\n",
        "  Origin[\"Self_Ter\"] = Origin[\"Self_Ter\"].shift(-829)\n",
        "  Origin[\"Stranger_Ter\"] = Origin[\"Stranger_Ter\"].shift(-829)\n",
        "\n",
        "  Origin[\"GM_Ter\"] = Origin[\"GM_Ter\"].shift(-829)\n",
        "  Origin[\"GO_Ter\"] = Origin[\"GO_Ter\"].shift(-829)\n",
        "  Origin[\"BO_Ter\"] = Origin[\"BO_Ter\"].shift(-829)\n",
        "  Origin[\"BM_Ter\"] = Origin[\"BM_Ter\"].shift(-829)\n",
        "\n",
        "  Origin[\"GM_Time\"] = Origin[\"GM_Time\"].shift(-829)\n",
        "  Origin[\"GO_Time\"] = Origin[\"GO_Time\"].shift(-829)\n",
        "  Origin[\"BO_Time\"] = Origin[\"BO_Time\"].shift(-829)\n",
        "  Origin[\"BM_Time\"] = Origin[\"BM_Time\"].shift(-829)\n",
        "\n",
        "  #Deleting unwanted columns\n",
        "  unwanted_columns = ['1Shape','1Congruence','1RT','1Score',\n",
        "                                                        '2Character','2Shape','2Congruence','2RT',\n",
        "                                                        '2Score','TimeDur_POSself','TimeDur_NEGself','TimeDur_POSother','TimeDur_NEGother']\n",
        "\n",
        "  Origin.drop(unwanted_columns, inplace=True, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "  #This creates a file name that is relevant to the data\n",
        "  FileName = (str('EZRC_4') + str(Origin['ID'][0]) + str(Origin['SEX'][0]) + str(Origin[\"Age\"][0]) + str(Origin['Health group'][0]) +str('.csv'))\n",
        "  #Save file\n",
        "  Origin.to_csv(r'/content/drive/MyDrive/EZ5/%s'%FileName, index = False)\n",
        "\n",
        "print('progress...')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWSY89PP4jXU",
        "outputId": "332a633f-1420-41e7-f0f2-a03ddc240c4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultant CSV after joining all CSV files at a particular location...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# setting the path for joining multiple files\n",
        "files = os.path.join(\"/content/drive/MyDrive/EZ_Outliers/\", \"*.csv\")\n",
        "\n",
        "# list of merged files returned\n",
        "files = glob.glob(files)\n",
        "\n",
        "print(\"Resultant CSV after joining all CSV files at a particular location...\");\n",
        "\n",
        "# joining files with concat and read_csv\n",
        "df = pd.concat(map(pd.read_csv, files), ignore_index=False)\n",
        "df.dropna()\n",
        "\n",
        "df.to_excel(r'/content/drive/MyDrive/CData/Cleaned_Results.xlsx', index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}